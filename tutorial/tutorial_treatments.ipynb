{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure/clairvoyance_logo.png\">\n",
    "\n",
    "# Clairvoyance: Treatment effects estimation\n",
    "\n",
    "## ML-AIM (http://vanderschaar-lab.com/)\n",
    "\n",
    "This notebook describes a user-guide for treatment effects estimation using the Clairvoyance framework. We consider the case of time-varying treatments where, given static and temporal features we want to estimate the effect of a single treatment or a sequence of treatments on the patient outcome. For instance, using the static data (demographic information), temporal data (vitals, lab tests) and treatments administered over time, we can estimate whether the patient will need the ventilator under different possible treatment plans. These counterfactual trajectories can then be used to decide which treatment plan will give the best patient outcome. \n",
    "\n",
    "- Rolling window counterfactual prediction:\n",
    "  - Example: Predict the effect of a sequence of treatments on the probability of the patient needing a ventilator. The projection horizon is equal to the length of the sequence of treatments for which we make the counterfactual predictions. \n",
    " \n",
    "<img src=\"figure/treatment-effects-definition.png\">\n",
    "\n",
    "To run this tutorial, you need:\n",
    "### Temporal and static datasets for training and testing\n",
    "\n",
    "If users come with their own temporal and static datasets for training and testing, the users should save those files as 'data_name_temporal_train_data_eav.csv.gz', 'data_name_static_train_data.csv.gz', 'data_name_temporal_test_data_eav.csv.gz', 'data_name_static_test_data.csv.gz' in '../datasets/data/data_name/' directory.\n",
    "\n",
    "Note: the temporal data should contain information about the treatments administered over time.\n",
    "\n",
    "### Assumptions needed for performing causal inference\n",
    "For the selected temoporal data, users should check the necesary assumptions for performing causal inference using the data, namely overlap (positivity) and no hidden confounders. Overlap means that at each timestep, each patient has non-zero probability of being assigned each treatment option, no hidden confounders involves considering all variables that are affecting the treatment assignment and patient outcome at each timestep. \n",
    "If these assumptions do not hold, they will obtain bias estimates of the treatment effects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series prediction pipeline summary\n",
    "\n",
    "<img src=\"figure/treatment-effects-block-diagram.png\">\n",
    "\n",
    "### Step 1: Load dataset\n",
    "  - Extract csv files from the original raw datasets in ../datasets/data/data_name/ directory.  \n",
    "  \n",
    "### Step 2: Preprocess dataset\n",
    "  - Preprocessing the raw data using various filters such as (1) replacing negative values to NaN, (2) do one-hot encidng for certain features, (3) do normalization.  \n",
    "  \n",
    "### Step 3: Define problem\n",
    "  - Set the time-series prediction problem that we want to solve. For treatment effects, we only consider the 'online' prediction problem as we are interested in estimating counterfactual outcomes at different timesteps throughtout the patient trajectory. In addition, set the label, set the maximum sequence length, and set the features in the temporal dataset that should be considered as treatments. We also define the metric for evaluation and the task itself (whether classification or regression).\n",
    "\n",
    "### Step 4: Impute dataset\n",
    "  - Impute missing values in the preprocessed static and temporal datasets and return complete datasets.\n",
    "  \n",
    "### Step 5: Feature selection\n",
    "  - Select the relevant static and temporal features to the labels. You can skip the feature selection (set feature selection method = None). For causal infernece, if feature selection is performed, one needs to ensure that the remaining features still satisfy the required identifiability assumptions. \n",
    "  \n",
    "### Step 6: Treatment effects model fit and predict\n",
    "  - After finishing the data preparation, we define the treatment effects models and train the model using the training dataset. The models capable of estimating counterfactual outcomes for a sequence of treatments into the future will have the option for selecting the projection horizon. After training, we use the trained model to estimating treatment effects on the testing dataset.\n",
    "  \n",
    "### Step 7: Visualize results\n",
    "  - Visualize the various results such as performance, factual and counterfactual predictions and uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import necessary packages\n",
    "\n",
    "Import necessary packages for the entire tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.realpath('..'))\n",
    "# sys.path.append('/Users/ioanabica/PycharmProjects/time-series-automl/')\n",
    "\n",
    "from utils import PipelineComposer\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load dataset\n",
    "\n",
    "Extract temporal and static datasets from 'data_name_temporal_train_data_eav.csv.gz', 'data_name_static_train_data.csv.gz', 'data_name_temporal_test_data_eav.csv.gz', 'data_name_static_test_data.csv.gz' in '../datasets/data/data_name/' directory.\n",
    "\n",
    "- CSVLoader: Load csv files from the original raw datasets in ../datasets/data/data_name/ directory.\n",
    "- file_names: mimic in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish data loading.\n"
     ]
    }
   ],
   "source": [
    "from datasets import CSVLoader\n",
    "\n",
    "# Define data name\n",
    "data_name = 'mimic_antibiotics'\n",
    "# Define data dictionary\n",
    "data_directory = '../datasets/data/'+data_name + '/' + data_name + '_'\n",
    "\n",
    "# Load train and test datasets\n",
    "data_loader_training = CSVLoader(static_file=data_directory + 'static_train_data.csv.gz',\n",
    "                                 temporal_file=data_directory + 'temporal_train_data_eav.csv.gz')\n",
    "\n",
    "data_loader_testing = CSVLoader(static_file=data_directory + 'static_test_data.csv.gz',\n",
    "                                temporal_file=data_directory + 'temporal_test_data_eav.csv.gz')\n",
    "\n",
    "dataset_training = data_loader_training.load()\n",
    "dataset_testing = data_loader_testing.load()\n",
    "\n",
    "print('Finish data loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess dataset\n",
    "\n",
    "Preprocess the raw data using multiple filters. In this tutorial, we replace all the negative values to NaN (using NegativeFilter), do one-hot encoding on 'admission_type' feature (using OneHotEncoder), and do MinMax Normalization (using Normalization). Preprocessing is done for both training and testing datasets. \n",
    "  - NegativeFilter: Replace negative values to NaN\n",
    "  - OneHotEncoder: One hot encoding certain features\n",
    "    - one_hot_encoding: input features that need to be one-hot encoded\n",
    "  - Normalization (3 options): MinMax, Standard, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish preprocessing.\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import FilterNegative, OneHotEncoder, Normalizer\n",
    "\n",
    "# (1) filter out negative values\n",
    "negative_filter = FilterNegative()\n",
    "# (2) one-hot encode categorical features\n",
    "one_hot_encoding = 'admission_type'\n",
    "onehot_encoder = OneHotEncoder(one_hot_encoding_features=[one_hot_encoding])\n",
    "# (3) Normalize features: 3 options (minmax, standard, none)\n",
    "normalization = 'minmax'\n",
    "normalizer = Normalizer(normalization)\n",
    "\n",
    "# Data preprocessing\n",
    "filter_pipeline = PipelineComposer(negative_filter, onehot_encoder, normalizer)\n",
    "\n",
    "dataset_training = filter_pipeline.fit_transform(dataset_training)\n",
    "dataset_testing = filter_pipeline.transform(dataset_testing)\n",
    "\n",
    "print('Finish preprocessing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define problem   \n",
    "\n",
    "Set the treatment-effects causal inference problem that we want to solve. As explained at the beginning of the notebook, estimating treatment effects over time makes sense only in the 'online' problem setting.  In addition, set the label, set the maximum sequence length, and set the treatment features. We also define the metric for evaluation and the task itself (whether classification or regression). In this tutorial, we predict the effect of treatments on ventilator usage. \n",
    "  - problem: 'online'(rolling window prediction) \n",
    "    - 'online': preditcion at every time stamps of the time-series\n",
    "  - max_seq_len: maximum sequence length of time-series sequence\n",
    "  - label_name: the column name for the label(s)\n",
    "  - treatment: the column name for treatment (currently only binare treatment is supported)\n",
    "  - window: x-hour ahead prediction (difference between consecutive time steps).\n",
    "  \n",
    "  - other parameters:\n",
    "    - metric_name: auc, apr, mse, mae\n",
    "    - task: classification or regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5429/5429 [00:09<00:00, 558.64it/s]\n",
      "100%|██████████| 5429/5429 [00:09<00:00, 595.12it/s]\n",
      "100%|██████████| 5429/5429 [00:09<00:00, 565.87it/s]\n",
      "100%|██████████| 5429/5429 [00:09<00:00, 561.87it/s]\n",
      "100%|██████████| 604/604 [00:01<00:00, 570.01it/s]\n",
      "100%|██████████| 604/604 [00:01<00:00, 597.84it/s]\n",
      "100%|██████████| 604/604 [00:01<00:00, 571.69it/s]\n",
      "100%|██████████| 604/604 [00:01<00:00, 569.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish defining problem.\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import ProblemMaker\n",
    "\n",
    "# Define parameters\n",
    "problem = 'online'\n",
    "max_seq_len = 20\n",
    "label_name = 'ventilator'\n",
    "treatment = ['antibiotics']\n",
    "window = 1\n",
    "\n",
    "# Define problem \n",
    "problem_maker = ProblemMaker(problem=problem, label=[label_name],\n",
    "                             max_seq_len=max_seq_len, treatment=treatment, window=window)\n",
    "\n",
    "dataset_training = problem_maker.fit_transform(dataset_training)\n",
    "dataset_testing = problem_maker.fit_transform(dataset_testing)\n",
    "\n",
    "# Set other parameters\n",
    "metric_name = 'auc'\n",
    "task = 'classification'\n",
    "\n",
    "metric_sets = [metric_name]\n",
    "metric_parameters =  {'problem': problem, 'label_name': [label_name]}\n",
    "\n",
    "print('Finish defining problem.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Impute dataset\n",
    "\n",
    "Impute missing values in the preprocessed static and temporal datasets and return complete datasets.\n",
    "  - Static imputation (6 options): mean, median, mice, missforest, knn, gain\n",
    "  - Temporal imputation (8 options): mean, median, linear, quadratic, cubic, spline, mrnn, tgain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5429/5429 [00:06<00:00, 857.10it/s]\n",
      "100%|██████████| 604/604 [00:00<00:00, 866.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish imputation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from imputation import Imputation\n",
    "\n",
    "# Set imputation models\n",
    "static_imputation_model = 'median'\n",
    "temporal_imputation_model = 'linear'\n",
    "\n",
    "# Impute the missing data\n",
    "static_imputation = Imputation(imputation_model_name = static_imputation_model, data_type = 'static')\n",
    "temporal_imputation = Imputation(imputation_model_name = temporal_imputation_model, data_type = 'temporal')\n",
    "\n",
    "imputation_pipeline = PipelineComposer(static_imputation, temporal_imputation)\n",
    "\n",
    "dataset_training = imputation_pipeline.fit_transform(dataset_training)\n",
    "dataset_testing = imputation_pipeline.transform(dataset_testing)\n",
    "\n",
    "print('Finish imputation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Feature selection\n",
    "\n",
    "Select the relevant static and temporal features to the labels. If you do not want, we can skip the feature selection (set feature selection method = None).\n",
    "  - feature selection method: \n",
    "      - feature_selection_model: greedy-addition, greedy-deletion, recursive-addition, recursive-deletion, None\n",
    "      - feature_number: selected featuer number\n",
    "      \n",
    "After feature selection, the user needs to ensure that the assumptions needed for causal inference still hold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish feature selection.\n"
     ]
    }
   ],
   "source": [
    "from feature_selection import FeatureSelection\n",
    "\n",
    "# Set feature selection parameters\n",
    "static_feature_selection_model = None\n",
    "temporal_feature_selection_model = None\n",
    "static_feature_selection_number = None\n",
    "temporal_feature_selection_number = None\n",
    "\n",
    "# Select relevant features\n",
    "static_feature_selection = \\\n",
    "FeatureSelection(feature_selection_model_name = static_feature_selection_model,\n",
    "                 feature_type = 'static', feature_number = static_feature_selection_number,\n",
    "                 task = task, metric_name = metric_name,\n",
    "                 metric_parameters = metric_parameters)\n",
    "\n",
    "temporal_feature_selection = \\\n",
    "FeatureSelection(feature_selection_model_name = temporal_feature_selection_model,\n",
    "                 feature_type = 'temporal', feature_number = temporal_feature_selection_number,\n",
    "                 task = task, metric_name = metric_name,\n",
    "                 metric_parameters = metric_parameters)\n",
    "\n",
    "feature_selection_pipeline = PipelineComposer(static_feature_selection, temporal_feature_selection)\n",
    "\n",
    "dataset_training = feature_selection_pipeline.fit_transform(dataset_training)\n",
    "dataset_testing = feature_selection_pipeline.transform(dataset_testing)\n",
    "\n",
    "print('Finish feature selection.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Treatment-effects model fit and predict\n",
    "\n",
    "After finishing the data preparation, we define the treatment effect models (3 options: Counterfactual Recurrent Network (CRN), Recurrent Marginal Structural Models (RMSNs) and GANITE). Note that GANITE is a treatments effect model for the static setting; the implementation of GANITE in this package processes the patient history by stacking the a number of previous timsteps specified by the user through stack_dim and can only be used for one-step ahead prediction of treatment effects. \n",
    "\n",
    "For CRN and RMSN, a projection_horizon can set when fitting the models for estimating counterfactual trajectories. The projection horizon is equal to the length of the sequence of treatments for which we make the counterfactual predictions.\n",
    "\n",
    "We then train the treatment effects model model using the training dataset. We set validation set as the 20% of the training set for early stopping and best model saving. \n",
    "\n",
    "After training, we use the trained model to:\n",
    "- predict the factual outcomes of the testing dataset.\n",
    "- estimate counterfactual trajectories for a sequence of future treatments. \n",
    "\n",
    "Each model has different types of hyperparameters that need to be set. \n",
    "\n",
    "- Hyperparameters needed for the Counterfactual Recurrent Network:\n",
    "  - hyperparameters for encoder:\n",
    "      - rnn_hidden_units: hidden dimensions in the LSTM unit\n",
    "      - rnn_keep_prob: keep probability used for variational dropout in the LSTM unit\n",
    "      - br_size: size of the balancing representation\n",
    "      - fc_hidden_units: hidden dimensions of the fully connected layers used for treatment classifier and predictor\n",
    "      - batch_size: number of samples in mini-batch\n",
    "      - num_epochs: number of epochs\n",
    "      - learning_rate: learning rate\n",
    "      - max_alpha: alpha controls the trade-off between building tratment invariant representations (domain discrimination) and being able to predict outcomes (outcome prediction); during training, CRN uses an exponentially increasing schedule for alpha from 0 to max_alpha\n",
    "  - hyperparameters for decoder:\n",
    "      - the decoder requires the same hyperparameters as the encoder with the exception of the rnn_hidden_units \n",
    "        which is set to be equal to the br_size of the encoder\n",
    "        \n",
    "        \n",
    "- Hyperparameters for Recurrent Marginal Structural Networks:\n",
    "    - hyperparameters for encoder:\n",
    "        - dropout_rate: dropout probability used for variational\n",
    "        - rnn_hidden_units: hidden dimensions in the LSTM unit\n",
    "        - batch_size: number of samples in mini-batch\n",
    "        - num_epochs: number of epochs\n",
    "        - learning_rate: learning rate\n",
    "        - max_norm: max gradient norm used for gradient clipping during training\n",
    "        \n",
    "    - hyperparameters for decoder:\n",
    "        - the decoder requires the same hyperparameters as the encoder. \n",
    "\n",
    "  \n",
    "- Hyperparameters for GANITE:\n",
    "  - batch size: number of samples in mini-batch\n",
    "  - alpha: parameter trading off between discriminator loss and supervised loss for the generator training\n",
    "  - learning_rate: learning rate\n",
    "  - hidden_units: hidden dimensions of the fully connected layers used in the networks\n",
    "  - stack_dim: number of timesteps to stack\n",
    "  \n",
    "  \n",
    "All models have the following common parameters:\n",
    "  - static_mode: how to utilize static features (concatenate or None)\n",
    "  - time_mode: how to utilize time information (concatenate or None)\n",
    "  - taks: 'classification' or 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Epoch 0 | total loss = 1.8494590520858765 | outcome loss = 0.6027544736862183 | treatment loss = 1.2467045783996582 | current alpha = 0.0 \n",
      "INFO:Epoch 0 Summary| Validation loss = 1.83298921585083 | Validation loss outcomes = 0.5925018191337585 | Validation loss treatments = 1.2404873371124268\n",
      "INFO:Epoch 1 | total loss = 1.789198875427246 | outcome loss = 0.5487242937088013 | treatment loss = 1.2404745817184448 | current alpha = 0.049958374957880025 \n",
      "INFO:Epoch 1 Summary| Validation loss = 1.719954252243042 | Validation loss outcomes = 0.505745530128479 | Validation loss treatments = 1.2142086029052734\n",
      "INFO:Epoch 2 | total loss = 1.7636284828186035 | outcome loss = 0.46056506037712097 | treatment loss = 1.3030633926391602 | current alpha = 0.0996679946249559 \n",
      "INFO:Epoch 2 Summary| Validation loss = 1.7645440101623535 | Validation loss outcomes = 0.5278290510177612 | Validation loss treatments = 1.2367149591445923\n",
      "INFO:Epoch 3 | total loss = 2.3475024700164795 | outcome loss = 0.41926756501197815 | treatment loss = 1.9282349348068237 | current alpha = 0.14888503362331806 \n",
      "INFO:Epoch 3 Summary| Validation loss = 2.4948158264160156 | Validation loss outcomes = 0.44885191321372986 | Validation loss treatments = 2.045964002609253\n",
      "INFO:Epoch 4 | total loss = 1.7783476114273071 | outcome loss = 0.4385874569416046 | treatment loss = 1.339760184288025 | current alpha = 0.197375320224904 \n",
      "INFO:Epoch 4 Summary| Validation loss = 1.914961338043213 | Validation loss outcomes = 0.5115558505058289 | Validation loss treatments = 1.4034054279327393\n",
      "INFO:Epoch 5 | total loss = 1.7050931453704834 | outcome loss = 0.45285722613334656 | treatment loss = 1.2522358894348145 | current alpha = 0.2449186624037092 \n",
      "INFO:Epoch 5 Summary| Validation loss = 1.7476232051849365 | Validation loss outcomes = 0.49957573413848877 | Validation loss treatments = 1.2480475902557373\n",
      "INFO:Epoch 6 | total loss = 1.7840218544006348 | outcome loss = 0.47521597146987915 | treatment loss = 1.3088058233261108 | current alpha = 0.2913126124515908 \n",
      "INFO:Epoch 6 Summary| Validation loss = 1.7960221767425537 | Validation loss outcomes = 0.48740702867507935 | Validation loss treatments = 1.30861496925354\n",
      "INFO:Epoch 7 | total loss = 1.820070743560791 | outcome loss = 0.38654273748397827 | treatment loss = 1.4335280656814575 | current alpha = 0.3363755443363323 \n",
      "INFO:Epoch 7 Summary| Validation loss = 1.9116723537445068 | Validation loss outcomes = 0.44023406505584717 | Validation loss treatments = 1.4714384078979492\n",
      "INFO:Epoch 8 | total loss = 2.249152183532715 | outcome loss = 0.4053754508495331 | treatment loss = 1.8437767028808594 | current alpha = 0.379948962255225 \n",
      "INFO:Epoch 8 Summary| Validation loss = 2.28914213180542 | Validation loss outcomes = 0.4226435422897339 | Validation loss treatments = 1.8664987087249756\n",
      "INFO:Epoch 9 | total loss = 1.7033236026763916 | outcome loss = 0.4016268849372864 | treatment loss = 1.3016966581344604 | current alpha = 0.4218990052500078 \n",
      "INFO:Epoch 9 Summary| Validation loss = 1.6727135181427002 | Validation loss outcomes = 0.43550682067871094 | Validation loss treatments = 1.2372066974639893\n",
      "INFO:Epoch 10 | total loss = 1.7632660865783691 | outcome loss = 0.46453750133514404 | treatment loss = 1.298728585243225 | current alpha = 0.4621171572600098 \n",
      "INFO:Epoch 10 Summary| Validation loss = 1.7264845371246338 | Validation loss outcomes = 0.4410054087638855 | Validation loss treatments = 1.2854790687561035\n",
      "INFO:Epoch 11 | total loss = 1.8129256963729858 | outcome loss = 0.4082143008708954 | treatment loss = 1.404711365699768 | current alpha = 0.5005202111902354 \n",
      "INFO:Epoch 11 Summary| Validation loss = 1.7945239543914795 | Validation loss outcomes = 0.4447104334831238 | Validation loss treatments = 1.349813461303711\n",
      "INFO:Epoch 12 | total loss = 1.6566983461380005 | outcome loss = 0.38169923424720764 | treatment loss = 1.2749991416931152 | current alpha = 0.5370495669980351 \n",
      "INFO:Epoch 12 Summary| Validation loss = 1.6810983419418335 | Validation loss outcomes = 0.41937071084976196 | Validation loss treatments = 1.2617275714874268\n",
      "INFO:Epoch 13 | total loss = 1.6049675941467285 | outcome loss = 0.3862561583518982 | treatment loss = 1.218711495399475 | current alpha = 0.5716699660851172 \n",
      "INFO:Epoch 13 Summary| Validation loss = 1.696982502937317 | Validation loss outcomes = 0.5095613598823547 | Validation loss treatments = 1.1874210834503174\n",
      "INFO:Epoch 14 | total loss = 1.7342028617858887 | outcome loss = 0.5071405172348022 | treatment loss = 1.2270623445510864 | current alpha = 0.6043677771171636 \n",
      "INFO:Epoch 14 Summary| Validation loss = 1.6312096118927002 | Validation loss outcomes = 0.4540890157222748 | Validation loss treatments = 1.1771206855773926\n",
      "INFO:Epoch 15 | total loss = 1.668874979019165 | outcome loss = 0.38990193605422974 | treatment loss = 1.27897310256958 | current alpha = 0.6351489523872873 \n",
      "INFO:Epoch 15 Summary| Validation loss = 1.630732774734497 | Validation loss outcomes = 0.4339176416397095 | Validation loss treatments = 1.1968151330947876\n",
      "INFO:Epoch 16 | total loss = 1.6983060836791992 | outcome loss = 0.41942378878593445 | treatment loss = 1.2788822650909424 | current alpha = 0.6640367702678489 \n",
      "INFO:Epoch 16 Summary| Validation loss = 1.629678726196289 | Validation loss outcomes = 0.4166543483734131 | Validation loss treatments = 1.213024377822876\n",
      "INFO:Epoch 17 | total loss = 1.6229838132858276 | outcome loss = 0.3738781213760376 | treatment loss = 1.24910569190979 | current alpha = 0.6910694698329305 \n",
      "INFO:Epoch 17 Summary| Validation loss = 1.6440098285675049 | Validation loss outcomes = 0.42564523220062256 | Validation loss treatments = 1.2183647155761719\n",
      "INFO:Epoch 18 | total loss = 1.6547670364379883 | outcome loss = 0.38143354654312134 | treatment loss = 1.2733335494995117 | current alpha = 0.7162978701990246 \n",
      "INFO:Epoch 18 Summary| Validation loss = 1.6298747062683105 | Validation loss outcomes = 0.41861677169799805 | Validation loss treatments = 1.211257815361023\n",
      "INFO:Epoch 19 | total loss = 1.621254801750183 | outcome loss = 0.3732616603374481 | treatment loss = 1.2479931116104126 | current alpha = 0.7397830512740042 \n",
      "INFO:Epoch 19 Summary| Validation loss = 1.6314222812652588 | Validation loss outcomes = 0.4268719255924225 | Validation loss treatments = 1.2045503854751587\n",
      "INFO:Epoch 20 | total loss = 1.6372168064117432 | outcome loss = 0.40271905064582825 | treatment loss = 1.2344977855682373 | current alpha = 0.7615941559557646 \n",
      "INFO:Epoch 20 Summary| Validation loss = 1.6335275173187256 | Validation loss outcomes = 0.4421551823616028 | Validation loss treatments = 1.1913723945617676\n",
      "INFO:Epoch 21 | total loss = 1.5925588607788086 | outcome loss = 0.3781891167163849 | treatment loss = 1.214369773864746 | current alpha = 0.7818063576087741 \n",
      "INFO:Epoch 21 Summary| Validation loss = 1.586315393447876 | Validation loss outcomes = 0.40964198112487793 | Validation loss treatments = 1.176673412322998\n",
      "INFO:Epoch 22 | total loss = 1.5800120830535889 | outcome loss = 0.37615835666656494 | treatment loss = 1.203853726387024 | current alpha = 0.8004990217606296 \n",
      "INFO:Epoch 22 Summary| Validation loss = 1.5916849374771118 | Validation loss outcomes = 0.4194090962409973 | Validation loss treatments = 1.1722757816314697\n",
      "INFO:Epoch 23 | total loss = 1.5994102954864502 | outcome loss = 0.3719055950641632 | treatment loss = 1.2275047302246094 | current alpha = 0.8177540779702877 \n",
      "INFO:Epoch 23 Summary| Validation loss = 1.6271073818206787 | Validation loss outcomes = 0.41331303119659424 | Validation loss treatments = 1.213794231414795\n",
      "INFO:Epoch 24 | total loss = 1.8306868076324463 | outcome loss = 0.41375240683555603 | treatment loss = 1.4169343709945679 | current alpha = 0.8336546070121553 \n",
      "INFO:Epoch 24 Summary| Validation loss = 1.8052306175231934 | Validation loss outcomes = 0.4952807128429413 | Validation loss treatments = 1.3099498748779297\n",
      "INFO:Epoch 25 | total loss = 1.834608793258667 | outcome loss = 0.5193683505058289 | treatment loss = 1.3152403831481934 | current alpha = 0.8482836399575131 \n",
      "INFO:Epoch 25 Summary| Validation loss = 1.7827783823013306 | Validation loss outcomes = 0.49284225702285767 | Validation loss treatments = 1.2899360656738281\n",
      "INFO:Epoch 26 | total loss = 1.6775990724563599 | outcome loss = 0.4372454583644867 | treatment loss = 1.2403535842895508 | current alpha = 0.8617231593133066 \n",
      "INFO:Epoch 26 Summary| Validation loss = 1.6962209939956665 | Validation loss outcomes = 0.4883250296115875 | Validation loss treatments = 1.2078959941864014\n",
      "INFO:Epoch 27 | total loss = 1.7429888248443604 | outcome loss = 0.48186397552490234 | treatment loss = 1.261124849319458 | current alpha = 0.874053287886007 \n",
      "INFO:Epoch 27 Summary| Validation loss = 1.8874294757843018 | Validation loss outcomes = 0.6544812917709351 | Validation loss treatments = 1.2329483032226562\n",
      "INFO:Epoch 28 | total loss = 1.7095580101013184 | outcome loss = 0.4032166600227356 | treatment loss = 1.3063414096832275 | current alpha = 0.8853516482022625 \n",
      "INFO:Epoch 28 Summary| Validation loss = 1.6948901414871216 | Validation loss outcomes = 0.42609667778015137 | Validation loss treatments = 1.2687934637069702\n",
      "INFO:Epoch 29 | total loss = 1.7867660522460938 | outcome loss = 0.39657092094421387 | treatment loss = 1.3901951313018799 | current alpha = 0.8956928738431646 \n",
      "INFO:Epoch 29 Summary| Validation loss = 1.7757253646850586 | Validation loss outcomes = 0.4325186014175415 | Validation loss treatments = 1.3432066440582275\n",
      "INFO:Epoch 30 | total loss = 1.7334219217300415 | outcome loss = 0.4113507568836212 | treatment loss = 1.3220711946487427 | current alpha = 0.9051482536448667 \n",
      "INFO:Epoch 30 Summary| Validation loss = 1.6830201148986816 | Validation loss outcomes = 0.4274630546569824 | Validation loss treatments = 1.2555570602416992\n",
      "INFO:Epoch 31 | total loss = 1.6378206014633179 | outcome loss = 0.399616003036499 | treatment loss = 1.2382045984268188 | current alpha = 0.9137854901178277 \n",
      "INFO:Epoch 31 Summary| Validation loss = 1.646960973739624 | Validation loss outcomes = 0.42002058029174805 | Validation loss treatments = 1.226940393447876\n",
      "INFO:Epoch 32 | total loss = 1.566046953201294 | outcome loss = 0.3953402638435364 | treatment loss = 1.1707067489624023 | current alpha = 0.9216685544064713 \n",
      "INFO:Epoch 32 Summary| Validation loss = 1.5981346368789673 | Validation loss outcomes = 0.44585275650024414 | Validation loss treatments = 1.1522818803787231\n",
      "INFO:Epoch 33 | total loss = 1.5423572063446045 | outcome loss = 0.37572798132896423 | treatment loss = 1.1666291952133179 | current alpha = 0.9288576214547277 \n",
      "INFO:Epoch 33 Summary| Validation loss = 1.560917854309082 | Validation loss outcomes = 0.4099903702735901 | Validation loss treatments = 1.1509275436401367\n",
      "INFO:Epoch 34 | total loss = 1.6387439966201782 | outcome loss = 0.3768077790737152 | treatment loss = 1.2619361877441406 | current alpha = 0.9354090706030991 \n",
      "INFO:Epoch 34 Summary| Validation loss = 1.629601001739502 | Validation loss outcomes = 0.41135886311531067 | Validation loss treatments = 1.2182421684265137\n",
      "INFO:Epoch 35 | total loss = 1.7866461277008057 | outcome loss = 0.3915475308895111 | treatment loss = 1.3950985670089722 | current alpha = 0.9413755384972873 \n",
      "INFO:Epoch 35 Summary| Validation loss = 1.7946869134902954 | Validation loss outcomes = 0.4114041030406952 | Validation loss treatments = 1.3832828998565674\n",
      "INFO:Epoch 36 | total loss = 1.8643585443496704 | outcome loss = 0.3936491310596466 | treatment loss = 1.4707094430923462 | current alpha = 0.9468060128462681 \n",
      "INFO:Epoch 36 Summary| Validation loss = 1.7916197776794434 | Validation loss outcomes = 0.4093853235244751 | Validation loss treatments = 1.3822343349456787\n",
      "INFO:Epoch 37 | total loss = 1.6982007026672363 | outcome loss = 0.3892030119895935 | treatment loss = 1.308997631072998 | current alpha = 0.9517459571646616 \n",
      "INFO:Epoch 37 Summary| Validation loss = 1.6861600875854492 | Validation loss outcomes = 0.4557318389415741 | Validation loss treatments = 1.2304283380508423\n",
      "INFO:Epoch 38 | total loss = 1.6629002094268799 | outcome loss = 0.4182383120059967 | treatment loss = 1.2446619272232056 | current alpha = 0.9562374581277389 \n",
      "INFO:Epoch 38 Summary| Validation loss = 1.6570497751235962 | Validation loss outcomes = 0.45189225673675537 | Validation loss treatments = 1.2051575183868408\n",
      "INFO:Epoch 39 | total loss = 1.6313774585723877 | outcome loss = 0.391925185918808 | treatment loss = 1.2394522428512573 | current alpha = 0.9603193885318451 \n",
      "INFO:Epoch 39 Summary| Validation loss = 1.6122472286224365 | Validation loss outcomes = 0.4217604994773865 | Validation loss treatments = 1.1904866695404053\n",
      "INFO:Epoch 40 | total loss = 1.5506316423416138 | outcome loss = 0.3742809295654297 | treatment loss = 1.176350712776184 | current alpha = 0.9640275800758169 \n",
      "INFO:Epoch 40 Summary| Validation loss = 1.5578815937042236 | Validation loss outcomes = 0.4051664173603058 | Validation loss treatments = 1.1527152061462402\n",
      "INFO:Epoch 41 | total loss = 1.556546926498413 | outcome loss = 0.373590350151062 | treatment loss = 1.182956576347351 | current alpha = 0.9673950012571182 \n",
      "INFO:Epoch 41 Summary| Validation loss = 1.606212854385376 | Validation loss outcomes = 0.4189113676548004 | Validation loss treatments = 1.1873016357421875\n",
      "INFO:Epoch 42 | total loss = 1.594269871711731 | outcome loss = 0.3753805160522461 | treatment loss = 1.2188893556594849 | current alpha = 0.9704519366134539 \n",
      "INFO:Epoch 42 Summary| Validation loss = 1.600258231163025 | Validation loss outcomes = 0.4013203978538513 | Validation loss treatments = 1.1989378929138184\n",
      "INFO:Epoch 43 | total loss = 1.6239194869995117 | outcome loss = 0.38857796788215637 | treatment loss = 1.2353415489196777 | current alpha = 0.9732261643446702 \n",
      "INFO:Epoch 43 Summary| Validation loss = 1.7152364253997803 | Validation loss outcomes = 0.5000335574150085 | Validation loss treatments = 1.215202808380127\n",
      "INFO:Epoch 44 | total loss = 1.659104824066162 | outcome loss = 0.39064401388168335 | treatment loss = 1.268460750579834 | current alpha = 0.9757431300314514 \n",
      "INFO:Epoch 44 Summary| Validation loss = 1.6783115863800049 | Validation loss outcomes = 0.4067020118236542 | Validation loss treatments = 1.2716095447540283\n",
      "INFO:Epoch 45 | total loss = 1.6823656558990479 | outcome loss = 0.39859429001808167 | treatment loss = 1.2837713956832886 | current alpha = 0.9780261147388136 \n",
      "INFO:Epoch 45 Summary| Validation loss = 1.6512317657470703 | Validation loss outcomes = 0.4110521674156189 | Validation loss treatments = 1.2401795387268066\n",
      "INFO:Epoch 46 | total loss = 1.6202352046966553 | outcome loss = 0.3769722878932953 | treatment loss = 1.2432628870010376 | current alpha = 0.9800963962661915 \n",
      "INFO:Epoch 46 Summary| Validation loss = 1.6415140628814697 | Validation loss outcomes = 0.41467157006263733 | Validation loss treatments = 1.2268424034118652\n",
      "INFO:Epoch 47 | total loss = 1.6382187604904175 | outcome loss = 0.3859765827655792 | treatment loss = 1.2522422075271606 | current alpha = 0.9819734026943041 \n",
      "INFO:Epoch 47 Summary| Validation loss = 1.5989406108856201 | Validation loss outcomes = 0.4026029706001282 | Validation loss treatments = 1.1963376998901367\n",
      "INFO:Epoch 48 | total loss = 1.664205551147461 | outcome loss = 0.3768073618412018 | treatment loss = 1.2873982191085815 | current alpha = 0.9836748576936802 \n",
      "INFO:Epoch 48 Summary| Validation loss = 1.6707215309143066 | Validation loss outcomes = 0.4223690927028656 | Validation loss treatments = 1.2483524084091187\n",
      "INFO:Epoch 49 | total loss = 1.6516222953796387 | outcome loss = 0.39712995290756226 | treatment loss = 1.2544924020767212 | current alpha = 0.9852169173114362 \n",
      "INFO:Epoch 49 Summary| Validation loss = 1.656749963760376 | Validation loss outcomes = 0.4412267804145813 | Validation loss treatments = 1.2155232429504395\n",
      "INFO:Epoch 50 | total loss = 1.6510322093963623 | outcome loss = 0.4078858196735382 | treatment loss = 1.2431464195251465 | current alpha = 0.9866142981514305 \n",
      "INFO:Epoch 50 Summary| Validation loss = 1.611083745956421 | Validation loss outcomes = 0.4107574224472046 | Validation loss treatments = 1.2003262042999268\n",
      "INFO:Epoch 51 | total loss = 1.632653832435608 | outcome loss = 0.38577544689178467 | treatment loss = 1.2468783855438232 | current alpha = 0.9878803970168315 \n",
      "INFO:Epoch 51 Summary| Validation loss = 1.6676182746887207 | Validation loss outcomes = 0.4568846821784973 | Validation loss treatments = 1.2107336521148682\n",
      "INFO:Epoch 52 | total loss = 1.689702033996582 | outcome loss = 0.4109114110469818 | treatment loss = 1.2787905931472778 | current alpha = 0.989027402201099 \n",
      "INFO:Epoch 52 Summary| Validation loss = 1.626729965209961 | Validation loss outcomes = 0.40718644857406616 | Validation loss treatments = 1.2195435762405396\n",
      "INFO:Epoch 53 | total loss = 1.5930733680725098 | outcome loss = 0.3798832595348358 | treatment loss = 1.2131900787353516 | current alpha = 0.9900663966998859 \n",
      "INFO:Epoch 53 Summary| Validation loss = 1.5829591751098633 | Validation loss outcomes = 0.407208651304245 | Validation loss treatments = 1.175750494003296\n",
      "INFO:Epoch 54 | total loss = 1.5839221477508545 | outcome loss = 0.3670148253440857 | treatment loss = 1.216907262802124 | current alpha = 0.9910074536781177 \n",
      "INFO:Epoch 54 Summary| Validation loss = 1.595118522644043 | Validation loss outcomes = 0.4087337255477905 | Validation loss treatments = 1.186384916305542\n",
      "INFO:Epoch 55 | total loss = 1.6139709949493408 | outcome loss = 0.3628922402858734 | treatment loss = 1.251078724861145 | current alpha = 0.9918597245682079 \n",
      "INFO:Epoch 55 Summary| Validation loss = 1.6180400848388672 | Validation loss outcomes = 0.4002572298049927 | Validation loss treatments = 1.217782735824585\n",
      "INFO:Epoch 56 | total loss = 1.6519681215286255 | outcome loss = 0.3796289265155792 | treatment loss = 1.2723392248153687 | current alpha = 0.9926315202011282 \n",
      "INFO:Epoch 56 Summary| Validation loss = 1.6411170959472656 | Validation loss outcomes = 0.41347289085388184 | Validation loss treatments = 1.2276442050933838\n",
      "INFO:Epoch 57 | total loss = 1.5776104927062988 | outcome loss = 0.3627127408981323 | treatment loss = 1.2148977518081665 | current alpha = 0.9933303853851734 \n",
      "INFO:Epoch 57 Summary| Validation loss = 1.6074192523956299 | Validation loss outcomes = 0.41765671968460083 | Validation loss treatments = 1.1897625923156738\n",
      "INFO:Epoch 58 | total loss = 1.5988125801086426 | outcome loss = 0.3858879506587982 | treatment loss = 1.212924599647522 | current alpha = 0.9939631673505833 \n",
      "INFO:Epoch 58 Summary| Validation loss = 1.5969167947769165 | Validation loss outcomes = 0.4014059901237488 | Validation loss treatments = 1.1955108642578125\n",
      "INFO:Epoch 59 | total loss = 1.6028051376342773 | outcome loss = 0.3758370578289032 | treatment loss = 1.2269680500030518 | current alpha = 0.9945360784739781 \n",
      "INFO:Epoch 59 Summary| Validation loss = 1.5974030494689941 | Validation loss outcomes = 0.399580180644989 | Validation loss treatments = 1.19782292842865\n",
      "INFO:Epoch 60 | total loss = 1.6167454719543457 | outcome loss = 0.3677366375923157 | treatment loss = 1.2490087747573853 | current alpha = 0.9950547536867307 \n",
      "INFO:Epoch 60 Summary| Validation loss = 1.614113450050354 | Validation loss outcomes = 0.39632266759872437 | Validation loss treatments = 1.2177907228469849\n",
      "INFO:Epoch 61 | total loss = 1.624104380607605 | outcome loss = 0.3621433973312378 | treatment loss = 1.2619609832763672 | current alpha = 0.9955243029574472 \n",
      "INFO:Epoch 61 Summary| Validation loss = 1.6263093948364258 | Validation loss outcomes = 0.4017137289047241 | Validation loss treatments = 1.2245957851409912\n",
      "INFO:Epoch 62 | total loss = 1.5943982601165771 | outcome loss = 0.35800230503082275 | treatment loss = 1.2363959550857544 | current alpha = 0.9959493592219002 \n",
      "INFO:Epoch 62 Summary| Validation loss = 1.6117126941680908 | Validation loss outcomes = 0.407226026058197 | Validation loss treatments = 1.204486608505249\n",
      "INFO:Epoch 63 | total loss = 1.6129894256591797 | outcome loss = 0.3612821102142334 | treatment loss = 1.2517073154449463 | current alpha = 0.9963341221150144 \n",
      "INFO:Epoch 63 Summary| Validation loss = 1.611128807067871 | Validation loss outcomes = 0.4012647569179535 | Validation loss treatments = 1.2098641395568848\n",
      "INFO:Epoch 64 | total loss = 1.6192626953125 | outcome loss = 0.36776238679885864 | treatment loss = 1.2515003681182861 | current alpha = 0.9966823978396511 \n",
      "INFO:Epoch 64 Summary| Validation loss = 1.614992618560791 | Validation loss outcomes = 0.3973565995693207 | Validation loss treatments = 1.2176361083984375\n",
      "INFO:Epoch 65 | total loss = 1.6186615228652954 | outcome loss = 0.380161851644516 | treatment loss = 1.238499641418457 | current alpha = 0.996997635486526 \n",
      "INFO:Epoch 65 Summary| Validation loss = 1.6232025623321533 | Validation loss outcomes = 0.4173271656036377 | Validation loss treatments = 1.2058753967285156\n",
      "INFO:Epoch 66 | total loss = 1.6082432270050049 | outcome loss = 0.3755183517932892 | treatment loss = 1.232724905014038 | current alpha = 0.9972829600991422 \n",
      "INFO:Epoch 66 Summary| Validation loss = 1.5885915756225586 | Validation loss outcomes = 0.3964606523513794 | Validation loss treatments = 1.1921309232711792\n",
      "INFO:Epoch 67 | total loss = 1.6075520515441895 | outcome loss = 0.3852226734161377 | treatment loss = 1.2223293781280518 | current alpha = 0.9975412027574453 \n",
      "INFO:Epoch 67 Summary| Validation loss = 1.5925312042236328 | Validation loss outcomes = 0.4034072756767273 | Validation loss treatments = 1.1891239881515503\n",
      "INFO:Epoch 68 | total loss = 1.6535030603408813 | outcome loss = 0.36399737000465393 | treatment loss = 1.2895057201385498 | current alpha = 0.9977749279342796 \n",
      "INFO:Epoch 68 Summary| Validation loss = 1.6328452825546265 | Validation loss outcomes = 0.4021022915840149 | Validation loss treatments = 1.2307429313659668\n",
      "INFO:Epoch 69 | total loss = 1.6436669826507568 | outcome loss = 0.3899989128112793 | treatment loss = 1.2536680698394775 | current alpha = 0.9979864583598288 \n",
      "INFO:Epoch 69 Summary| Validation loss = 1.6339560747146606 | Validation loss outcomes = 0.39853012561798096 | Validation loss treatments = 1.2354259490966797\n",
      "INFO:Epoch 70 | total loss = 1.5991290807724 | outcome loss = 0.36975178122520447 | treatment loss = 1.229377269744873 | current alpha = 0.9981778976111988 \n",
      "INFO:Epoch 70 Summary| Validation loss = 1.597299337387085 | Validation loss outcomes = 0.3931059241294861 | Validation loss treatments = 1.204193353652954\n",
      "INFO:Epoch 71 | total loss = 1.6244940757751465 | outcome loss = 0.398649126291275 | treatment loss = 1.2258449792861938 | current alpha = 0.9983511506272034 \n",
      "INFO:Epoch 71 Summary| Validation loss = 1.5833039283752441 | Validation loss outcomes = 0.3940647840499878 | Validation loss treatments = 1.189239263534546\n",
      "INFO:Epoch 72 | total loss = 1.5870665311813354 | outcome loss = 0.36453962326049805 | treatment loss = 1.2225269079208374 | current alpha = 0.9985079423323266 \n",
      "INFO:Epoch 72 Summary| Validation loss = 1.5851668119430542 | Validation loss outcomes = 0.39111238718032837 | Validation loss treatments = 1.194054365158081\n",
      "INFO:Epoch 73 | total loss = 1.6056588888168335 | outcome loss = 0.3738025724887848 | treatment loss = 1.231856346130371 | current alpha = 0.9986498345387345 \n",
      "INFO:Epoch 73 Summary| Validation loss = 1.5857133865356445 | Validation loss outcomes = 0.3894062638282776 | Validation loss treatments = 1.1963071823120117\n",
      "INFO:Epoch 74 | total loss = 1.598128318786621 | outcome loss = 0.37098246812820435 | treatment loss = 1.2271459102630615 | current alpha = 0.9987782412811312 \n",
      "INFO:Epoch 74 Summary| Validation loss = 1.5944362878799438 | Validation loss outcomes = 0.3959929347038269 | Validation loss treatments = 1.1984434127807617\n",
      "INFO:Epoch 75 | total loss = 1.5735758543014526 | outcome loss = 0.3486543893814087 | treatment loss = 1.224921464920044 | current alpha = 0.9988944427261528 \n",
      "INFO:Epoch 75 Summary| Validation loss = 1.5941119194030762 | Validation loss outcomes = 0.39110738039016724 | Validation loss treatments = 1.2030045986175537\n",
      "INFO:Epoch 76 | total loss = 1.6008327007293701 | outcome loss = 0.35730040073394775 | treatment loss = 1.2435322999954224 | current alpha = 0.998999597785841 \n",
      "INFO:Epoch 76 Summary| Validation loss = 1.6081483364105225 | Validation loss outcomes = 0.39780178666114807 | Validation loss treatments = 1.2103466987609863\n",
      "INFO:Epoch 77 | total loss = 1.6047427654266357 | outcome loss = 0.3569077253341675 | treatment loss = 1.2478350400924683 | current alpha = 0.999094755553519 \n",
      "INFO:Epoch 77 Summary| Validation loss = 1.6126558780670166 | Validation loss outcomes = 0.3961925804615021 | Validation loss treatments = 1.216463327407837\n",
      "INFO:Epoch 78 | total loss = 1.5760481357574463 | outcome loss = 0.35134491324424744 | treatment loss = 1.2247031927108765 | current alpha = 0.9991808656700278 \n",
      "INFO:Epoch 78 Summary| Validation loss = 1.59307861328125 | Validation loss outcomes = 0.3927139937877655 | Validation loss treatments = 1.200364589691162\n",
      "INFO:Epoch 79 | total loss = 1.5891475677490234 | outcome loss = 0.35801875591278076 | treatment loss = 1.2311288118362427 | current alpha = 0.9992587877187471 \n",
      "INFO:Epoch 79 Summary| Validation loss = 1.6012420654296875 | Validation loss outcomes = 0.39940863847732544 | Validation loss treatments = 1.2018334865570068\n",
      "INFO:Epoch 80 | total loss = 1.5899189710617065 | outcome loss = 0.36809659004211426 | treatment loss = 1.2218223810195923 | current alpha = 0.9993292997390673 \n",
      "INFO:Epoch 80 Summary| Validation loss = 1.5856528282165527 | Validation loss outcomes = 0.39140141010284424 | Validation loss treatments = 1.194251298904419\n",
      "INFO:Epoch 81 | total loss = 1.5810527801513672 | outcome loss = 0.3509504199028015 | treatment loss = 1.2301024198532104 | current alpha = 0.9993931059399423 \n",
      "INFO:Epoch 81 Summary| Validation loss = 1.587770938873291 | Validation loss outcomes = 0.393363893032074 | Validation loss treatments = 1.1944069862365723\n",
      "INFO:Epoch 82 | total loss = 1.5835261344909668 | outcome loss = 0.35317444801330566 | treatment loss = 1.2303516864776611 | current alpha = 0.9994508436877971 \n",
      "INFO:Epoch 82 Summary| Validation loss = 1.5891205072402954 | Validation loss outcomes = 0.3955550193786621 | Validation loss treatments = 1.1935654878616333\n",
      "INFO:Epoch 83 | total loss = 1.5824916362762451 | outcome loss = 0.35280928015708923 | treatment loss = 1.2296823263168335 | current alpha = 0.9995030898363211 \n",
      "INFO:Epoch 83 Summary| Validation loss = 1.5908704996109009 | Validation loss outcomes = 0.39415478706359863 | Validation loss treatments = 1.1967157125473022\n",
      "INFO:Epoch 84 | total loss = 1.6019017696380615 | outcome loss = 0.36006098985671997 | treatment loss = 1.2418407201766968 | current alpha = 0.9995503664595333 \n",
      "INFO:Epoch 84 Summary| Validation loss = 1.6054155826568604 | Validation loss outcomes = 0.389541894197464 | Validation loss treatments = 1.2158737182617188\n",
      "INFO:Epoch 85 | total loss = 1.5924465656280518 | outcome loss = 0.3407793641090393 | treatment loss = 1.2516672611236572 | current alpha = 0.9995931460438896 \n",
      "INFO:Epoch 85 Summary| Validation loss = 1.6107444763183594 | Validation loss outcomes = 0.38972362875938416 | Validation loss treatments = 1.2210209369659424\n",
      "INFO:Epoch 86 | total loss = 1.577021837234497 | outcome loss = 0.35642528533935547 | treatment loss = 1.2205965518951416 | current alpha = 0.9996318561900732 \n",
      "INFO:Epoch 86 Summary| Validation loss = 1.5888524055480957 | Validation loss outcomes = 0.3906203806400299 | Validation loss treatments = 1.1982319355010986\n",
      "INFO:Epoch 87 | total loss = 1.575054407119751 | outcome loss = 0.34379473328590393 | treatment loss = 1.2312597036361694 | current alpha = 0.9996668838704454 \n",
      "INFO:Epoch 87 Summary| Validation loss = 1.579816222190857 | Validation loss outcomes = 0.38479360938072205 | Validation loss treatments = 1.1950225830078125\n",
      "INFO:Epoch 88 | total loss = 1.5951483249664307 | outcome loss = 0.35351091623306274 | treatment loss = 1.2416374683380127 | current alpha = 0.9996985792838806 \n",
      "INFO:Epoch 88 Summary| Validation loss = 1.6135573387145996 | Validation loss outcomes = 0.3933590054512024 | Validation loss treatments = 1.2201982736587524\n",
      "INFO:Epoch 89 | total loss = 1.627197265625 | outcome loss = 0.3740418255329132 | treatment loss = 1.2531554698944092 | current alpha = 0.9997272593458408 \n",
      "INFO:Epoch 89 Summary| Validation loss = 1.638413667678833 | Validation loss outcomes = 0.4314314126968384 | Validation loss treatments = 1.2069823741912842\n",
      "INFO:Epoch 90 | total loss = 1.5925488471984863 | outcome loss = 0.36488741636276245 | treatment loss = 1.227661371231079 | current alpha = 0.9997532108480274 \n",
      "INFO:Epoch 90 Summary| Validation loss = 1.6016523838043213 | Validation loss outcomes = 0.40883374214172363 | Validation loss treatments = 1.1928186416625977\n",
      "INFO:Epoch 91 | total loss = 1.6001598834991455 | outcome loss = 0.3551732301712036 | treatment loss = 1.244986653327942 | current alpha = 0.9997766933187409 \n",
      "INFO:Epoch 91 Summary| Validation loss = 1.6175494194030762 | Validation loss outcomes = 0.4001743793487549 | Validation loss treatments = 1.2173750400543213\n",
      "INFO:Epoch 92 | total loss = 1.6013891696929932 | outcome loss = 0.3499809503555298 | treatment loss = 1.2514082193374634 | current alpha = 0.9997979416121845 \n",
      "INFO:Epoch 92 Summary| Validation loss = 1.645169973373413 | Validation loss outcomes = 0.4175850749015808 | Validation loss treatments = 1.227584958076477\n",
      "INFO:Epoch 93 | total loss = 1.6517717838287354 | outcome loss = 0.41320863366127014 | treatment loss = 1.2385631799697876 | current alpha = 0.9998171682522956 \n",
      "INFO:Epoch 93 Summary| Validation loss = 1.6126604080200195 | Validation loss outcomes = 0.405146062374115 | Validation loss treatments = 1.2075142860412598\n",
      "INFO:Epoch 94 | total loss = 1.6082446575164795 | outcome loss = 0.3616664409637451 | treatment loss = 1.2465782165527344 | current alpha = 0.9998345655542968 \n",
      "INFO:Epoch 94 Summary| Validation loss = 1.6059820652008057 | Validation loss outcomes = 0.3966074585914612 | Validation loss treatments = 1.2093745470046997\n",
      "INFO:Epoch 95 | total loss = 1.576036810874939 | outcome loss = 0.35876524448394775 | treatment loss = 1.2172715663909912 | current alpha = 0.999850307544979 \n",
      "INFO:Epoch 95 Summary| Validation loss = 1.6015877723693848 | Validation loss outcomes = 0.4072877764701843 | Validation loss treatments = 1.1943000555038452\n",
      "INFO:Epoch 96 | total loss = 1.580959677696228 | outcome loss = 0.3520869016647339 | treatment loss = 1.2288727760314941 | current alpha = 0.9998645517007607 \n",
      "INFO:Epoch 96 Summary| Validation loss = 1.6032156944274902 | Validation loss outcomes = 0.4067322015762329 | Validation loss treatments = 1.1964836120605469\n",
      "INFO:Epoch 97 | total loss = 1.6613709926605225 | outcome loss = 0.4010484516620636 | treatment loss = 1.2603225708007812 | current alpha = 0.9998774405207667 \n",
      "INFO:Epoch 97 Summary| Validation loss = 1.6192834377288818 | Validation loss outcomes = 0.40819400548934937 | Validation loss treatments = 1.2110893726348877\n",
      "INFO:Epoch 98 | total loss = 1.5702621936798096 | outcome loss = 0.3431718945503235 | treatment loss = 1.2270903587341309 | current alpha = 0.9998891029505543 \n",
      "INFO:Epoch 98 Summary| Validation loss = 1.5867137908935547 | Validation loss outcomes = 0.39252209663391113 | Validation loss treatments = 1.194191575050354\n",
      "INFO:Epoch 99 | total loss = 1.5521520376205444 | outcome loss = 0.34200799465179443 | treatment loss = 1.21014404296875 | current alpha = 0.9998996556706323 \n",
      "INFO:Epoch 99 Summary| Validation loss = 1.562199592590332 | Validation loss outcomes = 0.3821035623550415 | Validation loss treatments = 1.1800960302352905\n",
      "INFO:Epoch 0 | total loss = 1.4834938049316406 | outcome loss = 0.40179774165153503 | treatment loss = 1.0816960334777832 | current alpha = 0.0 \n",
      "INFO:Epoch 0 Summary| Validation loss = 1.6343109607696533 | Validation loss outcomes = 0.4695298671722412 | Validation loss treatments = 1.164781093597412\n",
      "INFO:Epoch 1 | total loss = 1.4673619270324707 | outcome loss = 0.3492909073829651 | treatment loss = 1.1180709600448608 | current alpha = 0.049958374957880025 \n",
      "INFO:Epoch 1 Summary| Validation loss = 1.5631380081176758 | Validation loss outcomes = 0.39188361167907715 | Validation loss treatments = 1.1712543964385986\n",
      "INFO:Epoch 2 | total loss = 1.5459249019622803 | outcome loss = 0.3479153513908386 | treatment loss = 1.1980094909667969 | current alpha = 0.0996679946249559 \n",
      "INFO:Epoch 2 Summary| Validation loss = 1.6521183252334595 | Validation loss outcomes = 0.38995885848999023 | Validation loss treatments = 1.2621593475341797\n",
      "INFO:Epoch 3 | total loss = 1.6320147514343262 | outcome loss = 0.3468381464481354 | treatment loss = 1.2851766347885132 | current alpha = 0.14888503362331806 \n",
      "INFO:Epoch 3 Summary| Validation loss = 1.6735793352127075 | Validation loss outcomes = 0.36795902252197266 | Validation loss treatments = 1.3056203126907349\n",
      "INFO:Epoch 4 | total loss = 1.5025768280029297 | outcome loss = 0.3257860541343689 | treatment loss = 1.1767908334732056 | current alpha = 0.197375320224904 \n",
      "INFO:Epoch 4 Summary| Validation loss = 1.6356256008148193 | Validation loss outcomes = 0.3536691665649414 | Validation loss treatments = 1.281956434249878\n",
      "INFO:Epoch 5 | total loss = 1.5479755401611328 | outcome loss = 0.3250386118888855 | treatment loss = 1.2229368686676025 | current alpha = 0.2449186624037092 \n",
      "INFO:Epoch 5 Summary| Validation loss = 1.60597825050354 | Validation loss outcomes = 0.3550524115562439 | Validation loss treatments = 1.250925898551941\n",
      "INFO:Epoch 6 | total loss = 1.6478855609893799 | outcome loss = 0.33727046847343445 | treatment loss = 1.310615062713623 | current alpha = 0.2913126124515908 \n",
      "INFO:Epoch 6 Summary| Validation loss = 1.6890708208084106 | Validation loss outcomes = 0.34839922189712524 | Validation loss treatments = 1.3406715393066406\n",
      "INFO:Epoch 7 | total loss = 1.481499195098877 | outcome loss = 0.31831949949264526 | treatment loss = 1.163179636001587 | current alpha = 0.3363755443363323 \n",
      "INFO:Epoch 7 Summary| Validation loss = 1.550125002861023 | Validation loss outcomes = 0.3516479730606079 | Validation loss treatments = 1.198477029800415\n",
      "INFO:Epoch 8 | total loss = 1.5399975776672363 | outcome loss = 0.32447126507759094 | treatment loss = 1.2155263423919678 | current alpha = 0.379948962255225 \n",
      "INFO:Epoch 8 Summary| Validation loss = 1.6163768768310547 | Validation loss outcomes = 0.35972392559051514 | Validation loss treatments = 1.256653070449829\n",
      "INFO:Epoch 9 | total loss = 1.5663520097732544 | outcome loss = 0.3655799925327301 | treatment loss = 1.2007720470428467 | current alpha = 0.4218990052500078 \n",
      "INFO:Epoch 9 Summary| Validation loss = 1.6170654296875 | Validation loss outcomes = 0.3579089045524597 | Validation loss treatments = 1.259156584739685\n",
      "INFO:Epoch 10 | total loss = 1.5347806215286255 | outcome loss = 0.32885563373565674 | treatment loss = 1.2059249877929688 | current alpha = 0.4621171572600098 \n",
      "INFO:Epoch 10 Summary| Validation loss = 1.5960657596588135 | Validation loss outcomes = 0.3477579355239868 | Validation loss treatments = 1.2483079433441162\n",
      "INFO:Epoch 11 | total loss = 1.5263357162475586 | outcome loss = 0.31047093868255615 | treatment loss = 1.2158647775650024 | current alpha = 0.5005202111902354 \n",
      "INFO:Epoch 11 Summary| Validation loss = 1.6074304580688477 | Validation loss outcomes = 0.35231533646583557 | Validation loss treatments = 1.255115032196045\n",
      "INFO:Epoch 12 | total loss = 1.5921634435653687 | outcome loss = 0.31468304991722107 | treatment loss = 1.2774803638458252 | current alpha = 0.5370495669980351 \n",
      "INFO:Epoch 12 Summary| Validation loss = 1.626023292541504 | Validation loss outcomes = 0.340248703956604 | Validation loss treatments = 1.2857747077941895\n",
      "INFO:Epoch 13 | total loss = 1.4290295839309692 | outcome loss = 0.31677374243736267 | treatment loss = 1.1122558116912842 | current alpha = 0.5716699660851172 \n",
      "INFO:Epoch 13 Summary| Validation loss = 1.5229928493499756 | Validation loss outcomes = 0.34481436014175415 | Validation loss treatments = 1.1781785488128662\n",
      "INFO:Epoch 14 | total loss = 1.7477604150772095 | outcome loss = 0.32633888721466064 | treatment loss = 1.4214215278625488 | current alpha = 0.6043677771171636 \n",
      "INFO:Epoch 14 Summary| Validation loss = 1.8090556859970093 | Validation loss outcomes = 0.35390445590019226 | Validation loss treatments = 1.4551513195037842\n",
      "INFO:Epoch 15 | total loss = 1.4852697849273682 | outcome loss = 0.3188477158546448 | treatment loss = 1.1664220094680786 | current alpha = 0.6351489523872873 \n",
      "INFO:Epoch 15 Summary| Validation loss = 1.5704550743103027 | Validation loss outcomes = 0.34501123428344727 | Validation loss treatments = 1.2254438400268555\n",
      "INFO:Epoch 16 | total loss = 1.5363597869873047 | outcome loss = 0.3099924921989441 | treatment loss = 1.2263672351837158 | current alpha = 0.6640367702678489 \n",
      "INFO:Epoch 16 Summary| Validation loss = 1.6149243116378784 | Validation loss outcomes = 0.36149030923843384 | Validation loss treatments = 1.2534339427947998\n",
      "INFO:Epoch 17 | total loss = 1.4841582775115967 | outcome loss = 0.31509435176849365 | treatment loss = 1.169063925743103 | current alpha = 0.6910694698329305 \n",
      "INFO:Epoch 17 Summary| Validation loss = 1.5678550004959106 | Validation loss outcomes = 0.3454188108444214 | Validation loss treatments = 1.2224361896514893\n",
      "INFO:Epoch 18 | total loss = 1.5537500381469727 | outcome loss = 0.30860042572021484 | treatment loss = 1.2451496124267578 | current alpha = 0.7162978701990246 \n",
      "INFO:Epoch 18 Summary| Validation loss = 1.6477046012878418 | Validation loss outcomes = 0.3502365052700043 | Validation loss treatments = 1.2974680662155151\n",
      "INFO:Epoch 19 | total loss = 1.5310078859329224 | outcome loss = 0.33329471945762634 | treatment loss = 1.1977131366729736 | current alpha = 0.7397830512740042 \n",
      "INFO:Epoch 19 Summary| Validation loss = 1.5281059741973877 | Validation loss outcomes = 0.34517472982406616 | Validation loss treatments = 1.1829314231872559\n",
      "INFO:Epoch 20 | total loss = 1.5258182287216187 | outcome loss = 0.31730565428733826 | treatment loss = 1.208512544631958 | current alpha = 0.7615941559557646 \n",
      "INFO:Epoch 20 Summary| Validation loss = 1.6011875867843628 | Validation loss outcomes = 0.34713664650917053 | Validation loss treatments = 1.2540509700775146\n",
      "INFO:Epoch 21 | total loss = 1.5734171867370605 | outcome loss = 0.3222058117389679 | treatment loss = 1.251211404800415 | current alpha = 0.7818063576087741 \n",
      "INFO:Epoch 21 Summary| Validation loss = 1.5983245372772217 | Validation loss outcomes = 0.34982186555862427 | Validation loss treatments = 1.2485026121139526\n",
      "INFO:Epoch 22 | total loss = 1.5306652784347534 | outcome loss = 0.33029818534851074 | treatment loss = 1.2003670930862427 | current alpha = 0.8004990217606296 \n",
      "INFO:Epoch 22 Summary| Validation loss = 1.5881450176239014 | Validation loss outcomes = 0.33997902274131775 | Validation loss treatments = 1.2481659650802612\n",
      "INFO:Epoch 23 | total loss = 1.5276376008987427 | outcome loss = 0.3055000603199005 | treatment loss = 1.2221375703811646 | current alpha = 0.8177540779702877 \n",
      "INFO:Epoch 23 Summary| Validation loss = 1.6119978427886963 | Validation loss outcomes = 0.34551694989204407 | Validation loss treatments = 1.2664809226989746\n",
      "INFO:Epoch 24 | total loss = 1.4821679592132568 | outcome loss = 0.30868154764175415 | treatment loss = 1.1734864711761475 | current alpha = 0.8336546070121553 \n",
      "INFO:Epoch 24 Summary| Validation loss = 1.5469765663146973 | Validation loss outcomes = 0.34267759323120117 | Validation loss treatments = 1.204298973083496\n",
      "INFO:Epoch 25 | total loss = 1.7035810947418213 | outcome loss = 0.3841833174228668 | treatment loss = 1.3193978071212769 | current alpha = 0.8482836399575131 \n",
      "INFO:Epoch 25 Summary| Validation loss = 1.7161847352981567 | Validation loss outcomes = 0.3713427782058716 | Validation loss treatments = 1.3448419570922852\n",
      "INFO:Epoch 26 | total loss = 1.577289342880249 | outcome loss = 0.3320563733577728 | treatment loss = 1.2452329397201538 | current alpha = 0.8617231593133066 \n",
      "INFO:Epoch 26 Summary| Validation loss = 1.6238386631011963 | Validation loss outcomes = 0.3560672998428345 | Validation loss treatments = 1.2677712440490723\n",
      "INFO:Epoch 27 | total loss = 1.6518263816833496 | outcome loss = 0.39845961332321167 | treatment loss = 1.2533668279647827 | current alpha = 0.874053287886007 \n",
      "INFO:Epoch 27 Summary| Validation loss = 1.6247055530548096 | Validation loss outcomes = 0.3430781960487366 | Validation loss treatments = 1.2816272974014282\n",
      "INFO:Epoch 28 | total loss = 1.5454292297363281 | outcome loss = 0.312866747379303 | treatment loss = 1.2325624227523804 | current alpha = 0.8853516482022625 \n",
      "INFO:Epoch 28 Summary| Validation loss = 1.6318390369415283 | Validation loss outcomes = 0.3434557318687439 | Validation loss treatments = 1.2883833646774292\n",
      "INFO:Epoch 29 | total loss = 1.5547285079956055 | outcome loss = 0.31700626015663147 | treatment loss = 1.2377222776412964 | current alpha = 0.8956928738431646 \n",
      "INFO:Epoch 29 Summary| Validation loss = 1.6388084888458252 | Validation loss outcomes = 0.34126925468444824 | Validation loss treatments = 1.2975393533706665\n",
      "INFO:Epoch 30 | total loss = 1.4330570697784424 | outcome loss = 0.3042985498905182 | treatment loss = 1.1287585496902466 | current alpha = 0.9051482536448667 \n",
      "INFO:Epoch 30 Summary| Validation loss = 1.513746738433838 | Validation loss outcomes = 0.3377869129180908 | Validation loss treatments = 1.1759599447250366\n",
      "INFO:Epoch 31 | total loss = 1.5528459548950195 | outcome loss = 0.3222815990447998 | treatment loss = 1.2305643558502197 | current alpha = 0.9137854901178277 \n",
      "INFO:Epoch 31 Summary| Validation loss = 1.638548493385315 | Validation loss outcomes = 0.33729541301727295 | Validation loss treatments = 1.301253080368042\n",
      "INFO:Epoch 32 | total loss = 1.4765175580978394 | outcome loss = 0.307140588760376 | treatment loss = 1.1693769693374634 | current alpha = 0.9216685544064713 \n",
      "INFO:Epoch 32 Summary| Validation loss = 1.5506887435913086 | Validation loss outcomes = 0.3389930725097656 | Validation loss treatments = 1.211695671081543\n",
      "INFO:Epoch 33 | total loss = 1.5863869190216064 | outcome loss = 0.3112453818321228 | treatment loss = 1.2751414775848389 | current alpha = 0.9288576214547277 \n",
      "INFO:Epoch 33 Summary| Validation loss = 1.6273671388626099 | Validation loss outcomes = 0.33569449186325073 | Validation loss treatments = 1.291672706604004\n",
      "INFO:Epoch 34 | total loss = 1.4560930728912354 | outcome loss = 0.30946749448776245 | treatment loss = 1.1466255187988281 | current alpha = 0.9354090706030991 \n",
      "INFO:Epoch 34 Summary| Validation loss = 1.5337494611740112 | Validation loss outcomes = 0.33384212851524353 | Validation loss treatments = 1.1999073028564453\n",
      "INFO:Epoch 35 | total loss = 1.5463489294052124 | outcome loss = 0.315750390291214 | treatment loss = 1.2305985689163208 | current alpha = 0.9413755384972873 \n",
      "INFO:Epoch 35 Summary| Validation loss = 1.603792667388916 | Validation loss outcomes = 0.33513885736465454 | Validation loss treatments = 1.2686538696289062\n",
      "INFO:Epoch 36 | total loss = 1.5426080226898193 | outcome loss = 0.30630815029144287 | treatment loss = 1.2362998723983765 | current alpha = 0.9468060128462681 \n",
      "INFO:Epoch 36 Summary| Validation loss = 1.5993995666503906 | Validation loss outcomes = 0.339905709028244 | Validation loss treatments = 1.2594938278198242\n",
      "INFO:Epoch 37 | total loss = 1.4765334129333496 | outcome loss = 0.3107336163520813 | treatment loss = 1.1657997369766235 | current alpha = 0.9517459571646616 \n",
      "INFO:Epoch 37 Summary| Validation loss = 1.5533270835876465 | Validation loss outcomes = 0.3355324864387512 | Validation loss treatments = 1.21779465675354\n",
      "INFO:Epoch 38 | total loss = 1.6092888116836548 | outcome loss = 0.3365500867366791 | treatment loss = 1.2727386951446533 | current alpha = 0.9562374581277389 \n",
      "INFO:Epoch 38 Summary| Validation loss = 1.645674228668213 | Validation loss outcomes = 0.3342647850513458 | Validation loss treatments = 1.3114094734191895\n",
      "INFO:Epoch 39 | total loss = 1.50264573097229 | outcome loss = 0.3136596977710724 | treatment loss = 1.18898606300354 | current alpha = 0.9603193885318451 \n",
      "INFO:Epoch 39 Summary| Validation loss = 1.5583503246307373 | Validation loss outcomes = 0.33519667387008667 | Validation loss treatments = 1.2231537103652954\n",
      "INFO:Epoch 40 | total loss = 1.5527795553207397 | outcome loss = 0.3083052933216095 | treatment loss = 1.2444742918014526 | current alpha = 0.9640275800758169 \n",
      "INFO:Epoch 40 Summary| Validation loss = 1.635907530784607 | Validation loss outcomes = 0.3489930033683777 | Validation loss treatments = 1.286914587020874\n",
      "INFO:Epoch 41 | total loss = 1.4749889373779297 | outcome loss = 0.30957677960395813 | treatment loss = 1.165412187576294 | current alpha = 0.9673950012571182 \n",
      "INFO:Epoch 41 Summary| Validation loss = 1.5431530475616455 | Validation loss outcomes = 0.33449026942253113 | Validation loss treatments = 1.2086628675460815\n",
      "INFO:Epoch 42 | total loss = 1.519890308380127 | outcome loss = 0.30748897790908813 | treatment loss = 1.212401270866394 | current alpha = 0.9704519366134539 \n",
      "INFO:Epoch 42 Summary| Validation loss = 1.6043009757995605 | Validation loss outcomes = 0.34324753284454346 | Validation loss treatments = 1.261053442955017\n",
      "INFO:Epoch 43 | total loss = 1.5034846067428589 | outcome loss = 0.3124782145023346 | treatment loss = 1.1910064220428467 | current alpha = 0.9732261643446702 \n",
      "INFO:Epoch 43 Summary| Validation loss = 1.5751469135284424 | Validation loss outcomes = 0.33367618918418884 | Validation loss treatments = 1.2414705753326416\n",
      "INFO:Epoch 44 | total loss = 1.4792572259902954 | outcome loss = 0.3056240975856781 | treatment loss = 1.173633098602295 | current alpha = 0.9757431300314514 \n",
      "INFO:Epoch 44 Summary| Validation loss = 1.5812983512878418 | Validation loss outcomes = 0.33737480640411377 | Validation loss treatments = 1.2439234256744385\n",
      "INFO:Epoch 45 | total loss = 1.5674188137054443 | outcome loss = 0.32880502939224243 | treatment loss = 1.2386138439178467 | current alpha = 0.9780261147388136 \n",
      "INFO:Epoch 45 Summary| Validation loss = 1.589414358139038 | Validation loss outcomes = 0.33561933040618896 | Validation loss treatments = 1.2537950277328491\n",
      "INFO:Epoch 46 | total loss = 1.5034767389297485 | outcome loss = 0.3181503117084503 | treatment loss = 1.1853264570236206 | current alpha = 0.9800963962661915 \n",
      "INFO:Epoch 46 Summary| Validation loss = 1.5678353309631348 | Validation loss outcomes = 0.3445640206336975 | Validation loss treatments = 1.223271369934082\n",
      "INFO:Epoch 47 | total loss = 1.506956696510315 | outcome loss = 0.30708417296409607 | treatment loss = 1.1998724937438965 | current alpha = 0.9819734026943041 \n",
      "INFO:Epoch 47 Summary| Validation loss = 1.5770680904388428 | Validation loss outcomes = 0.3346676826477051 | Validation loss treatments = 1.2424004077911377\n",
      "INFO:Epoch 48 | total loss = 1.5903817415237427 | outcome loss = 0.33037158846855164 | treatment loss = 1.2600101232528687 | current alpha = 0.9836748576936802 \n",
      "INFO:Epoch 48 Summary| Validation loss = 1.5938351154327393 | Validation loss outcomes = 0.334242045879364 | Validation loss treatments = 1.2595930099487305\n",
      "INFO:Epoch 49 | total loss = 1.5358598232269287 | outcome loss = 0.3466474115848541 | treatment loss = 1.189212441444397 | current alpha = 0.9852169173114362 \n",
      "INFO:Epoch 49 Summary| Validation loss = 1.5661232471466064 | Validation loss outcomes = 0.3355731964111328 | Validation loss treatments = 1.2305500507354736\n",
      "INFO:Epoch 50 | total loss = 1.5039939880371094 | outcome loss = 0.315633088350296 | treatment loss = 1.1883609294891357 | current alpha = 0.9866142981514305 \n",
      "INFO:Epoch 50 Summary| Validation loss = 1.5774445533752441 | Validation loss outcomes = 0.33491250872612 | Validation loss treatments = 1.2425320148468018\n",
      "INFO:Epoch 51 | total loss = 1.4732863903045654 | outcome loss = 0.3052244782447815 | treatment loss = 1.1680618524551392 | current alpha = 0.9878803970168315 \n",
      "INFO:Epoch 51 Summary| Validation loss = 1.5537302494049072 | Validation loss outcomes = 0.3331327438354492 | Validation loss treatments = 1.220597505569458\n",
      "INFO:Epoch 52 | total loss = 1.5271135568618774 | outcome loss = 0.3079816401004791 | treatment loss = 1.2191319465637207 | current alpha = 0.989027402201099 \n",
      "INFO:Epoch 52 Summary| Validation loss = 1.5974926948547363 | Validation loss outcomes = 0.33672037720680237 | Validation loss treatments = 1.2607722282409668\n",
      "INFO:Epoch 53 | total loss = 1.5047556161880493 | outcome loss = 0.311662882566452 | treatment loss = 1.193092703819275 | current alpha = 0.9900663966998859 \n",
      "INFO:Epoch 53 Summary| Validation loss = 1.5661373138427734 | Validation loss outcomes = 0.33572396636009216 | Validation loss treatments = 1.2304131984710693\n",
      "INFO:Epoch 54 | total loss = 1.5000653266906738 | outcome loss = 0.31861430406570435 | treatment loss = 1.1814509630203247 | current alpha = 0.9910074536781177 \n",
      "INFO:Epoch 54 Summary| Validation loss = 1.5654442310333252 | Validation loss outcomes = 0.33504071831703186 | Validation loss treatments = 1.2304034233093262\n",
      "INFO:Epoch 55 | total loss = 1.5376638174057007 | outcome loss = 0.32246115803718567 | treatment loss = 1.2152026891708374 | current alpha = 0.9918597245682079 \n",
      "INFO:Epoch 55 Summary| Validation loss = 1.579674482345581 | Validation loss outcomes = 0.33421099185943604 | Validation loss treatments = 1.2454633712768555\n",
      "INFO:Epoch 56 | total loss = 1.5270615816116333 | outcome loss = 0.3213423192501068 | treatment loss = 1.205719232559204 | current alpha = 0.9926315202011282 \n",
      "INFO:Epoch 56 Summary| Validation loss = 1.5736851692199707 | Validation loss outcomes = 0.33340615034103394 | Validation loss treatments = 1.2402790784835815\n",
      "INFO:Epoch 57 | total loss = 1.498014211654663 | outcome loss = 0.31596800684928894 | treatment loss = 1.1820461750030518 | current alpha = 0.9933303853851734 \n",
      "INFO:Epoch 57 Summary| Validation loss = 1.5742961168289185 | Validation loss outcomes = 0.3370974659919739 | Validation loss treatments = 1.2371985912322998\n",
      "INFO:Epoch 58 | total loss = 1.478642225265503 | outcome loss = 0.30527129769325256 | treatment loss = 1.1733709573745728 | current alpha = 0.9939631673505833 \n",
      "INFO:Epoch 58 Summary| Validation loss = 1.5779104232788086 | Validation loss outcomes = 0.3387189507484436 | Validation loss treatments = 1.2391915321350098\n",
      "INFO:Epoch 59 | total loss = 1.5454168319702148 | outcome loss = 0.319325715303421 | treatment loss = 1.2260911464691162 | current alpha = 0.9945360784739781 \n",
      "INFO:Epoch 59 Summary| Validation loss = 1.5850164890289307 | Validation loss outcomes = 0.33412089943885803 | Validation loss treatments = 1.2508957386016846\n",
      "INFO:Epoch 60 | total loss = 1.5323224067687988 | outcome loss = 0.32370200753211975 | treatment loss = 1.2086204290390015 | current alpha = 0.9950547536867307 \n",
      "INFO:Epoch 60 Summary| Validation loss = 1.56332528591156 | Validation loss outcomes = 0.33407798409461975 | Validation loss treatments = 1.2292473316192627\n",
      "INFO:Epoch 61 | total loss = 1.4617688655853271 | outcome loss = 0.3054526448249817 | treatment loss = 1.1563162803649902 | current alpha = 0.9955243029574472 \n",
      "INFO:Epoch 61 Summary| Validation loss = 1.5659291744232178 | Validation loss outcomes = 0.33528709411621094 | Validation loss treatments = 1.2306420803070068\n",
      "INFO:Epoch 62 | total loss = 1.5247414112091064 | outcome loss = 0.3068782091140747 | treatment loss = 1.2178632020950317 | current alpha = 0.9959493592219002 \n",
      "INFO:Epoch 62 Summary| Validation loss = 1.5937342643737793 | Validation loss outcomes = 0.3355242908000946 | Validation loss treatments = 1.2582099437713623\n",
      "INFO:Epoch 63 | total loss = 1.4815657138824463 | outcome loss = 0.31002119183540344 | treatment loss = 1.1715445518493652 | current alpha = 0.9963341221150144 \n",
      "INFO:Epoch 63 Summary| Validation loss = 1.569288730621338 | Validation loss outcomes = 0.3367300033569336 | Validation loss treatments = 1.2325587272644043\n",
      "INFO:Epoch 64 | total loss = 1.4836339950561523 | outcome loss = 0.30826765298843384 | treatment loss = 1.1753662824630737 | current alpha = 0.9966823978396511 \n",
      "INFO:Epoch 64 Summary| Validation loss = 1.5646154880523682 | Validation loss outcomes = 0.3372678756713867 | Validation loss treatments = 1.2273476123809814\n",
      "INFO:Epoch 65 | total loss = 1.5074567794799805 | outcome loss = 0.3066835105419159 | treatment loss = 1.2007732391357422 | current alpha = 0.996997635486526 \n",
      "INFO:Epoch 65 Summary| Validation loss = 1.597247838973999 | Validation loss outcomes = 0.33464714884757996 | Validation loss treatments = 1.2626006603240967\n",
      "INFO:Epoch 66 | total loss = 1.489970326423645 | outcome loss = 0.3070012032985687 | treatment loss = 1.182969093322754 | current alpha = 0.9972829600991422 \n",
      "INFO:Epoch 66 Summary| Validation loss = 1.5412169694900513 | Validation loss outcomes = 0.3349248170852661 | Validation loss treatments = 1.2062921524047852\n",
      "INFO:Epoch 67 | total loss = 1.5217971801757812 | outcome loss = 0.3068965673446655 | treatment loss = 1.2149006128311157 | current alpha = 0.9975412027574453 \n",
      "INFO:Epoch 67 Summary| Validation loss = 1.5894169807434082 | Validation loss outcomes = 0.3362749218940735 | Validation loss treatments = 1.2531418800354004\n",
      "INFO:Epoch 68 | total loss = 1.5083270072937012 | outcome loss = 0.3221168518066406 | treatment loss = 1.1862101554870605 | current alpha = 0.9977749279342796 \n",
      "INFO:Epoch 68 Summary| Validation loss = 1.5699915885925293 | Validation loss outcomes = 0.33483022451400757 | Validation loss treatments = 1.235161304473877\n",
      "INFO:Epoch 69 | total loss = 1.4788159132003784 | outcome loss = 0.31053125858306885 | treatment loss = 1.1682846546173096 | current alpha = 0.9979864583598288 \n",
      "INFO:Epoch 69 Summary| Validation loss = 1.5521607398986816 | Validation loss outcomes = 0.33275675773620605 | Validation loss treatments = 1.2194039821624756\n",
      "INFO:Epoch 70 | total loss = 1.517493486404419 | outcome loss = 0.30802395939826965 | treatment loss = 1.2094695568084717 | current alpha = 0.9981778976111988 \n",
      "INFO:Epoch 70 Summary| Validation loss = 1.581406831741333 | Validation loss outcomes = 0.33389437198638916 | Validation loss treatments = 1.2475124597549438\n",
      "INFO:Epoch 71 | total loss = 1.4989651441574097 | outcome loss = 0.30542945861816406 | treatment loss = 1.1935356855392456 | current alpha = 0.9983511506272034 \n",
      "INFO:Epoch 71 Summary| Validation loss = 1.5654933452606201 | Validation loss outcomes = 0.336036741733551 | Validation loss treatments = 1.2294566631317139\n",
      "INFO:Epoch 72 | total loss = 1.5173133611679077 | outcome loss = 0.3185677230358124 | treatment loss = 1.198745608329773 | current alpha = 0.9985079423323266 \n",
      "INFO:Epoch 72 Summary| Validation loss = 1.5813868045806885 | Validation loss outcomes = 0.3347174823284149 | Validation loss treatments = 1.2466692924499512\n",
      "INFO:Epoch 73 | total loss = 1.4984886646270752 | outcome loss = 0.304618775844574 | treatment loss = 1.193869948387146 | current alpha = 0.9986498345387345 \n",
      "INFO:Epoch 73 Summary| Validation loss = 1.5958209037780762 | Validation loss outcomes = 0.33555278182029724 | Validation loss treatments = 1.260267972946167\n",
      "INFO:Epoch 74 | total loss = 1.4816147089004517 | outcome loss = 0.311752051115036 | treatment loss = 1.1698626279830933 | current alpha = 0.9987782412811312 \n",
      "INFO:Epoch 74 Summary| Validation loss = 1.5473064184188843 | Validation loss outcomes = 0.33494412899017334 | Validation loss treatments = 1.212362289428711\n",
      "INFO:Epoch 75 | total loss = 1.5372796058654785 | outcome loss = 0.3219488561153412 | treatment loss = 1.215330719947815 | current alpha = 0.9988944427261528 \n",
      "INFO:Epoch 75 Summary| Validation loss = 1.6097779273986816 | Validation loss outcomes = 0.33557814359664917 | Validation loss treatments = 1.2741997241973877\n",
      "INFO:Epoch 76 | total loss = 1.5001535415649414 | outcome loss = 0.30407196283340454 | treatment loss = 1.196081519126892 | current alpha = 0.998999597785841 \n",
      "INFO:Epoch 76 Summary| Validation loss = 1.573671817779541 | Validation loss outcomes = 0.3377326726913452 | Validation loss treatments = 1.2359390258789062\n",
      "INFO:Epoch 77 | total loss = 1.5350313186645508 | outcome loss = 0.3089432120323181 | treatment loss = 1.226088047027588 | current alpha = 0.999094755553519 \n",
      "INFO:Epoch 77 Summary| Validation loss = 1.5945894718170166 | Validation loss outcomes = 0.3357474207878113 | Validation loss treatments = 1.2588419914245605\n",
      "INFO:Epoch 78 | total loss = 1.4778972864151 | outcome loss = 0.3053748309612274 | treatment loss = 1.1725224256515503 | current alpha = 0.9991808656700278 \n",
      "INFO:Epoch 78 Summary| Validation loss = 1.5619726181030273 | Validation loss outcomes = 0.3366531729698181 | Validation loss treatments = 1.225319504737854\n",
      "INFO:Epoch 79 | total loss = 1.5446052551269531 | outcome loss = 0.304608553647995 | treatment loss = 1.2399966716766357 | current alpha = 0.9992587877187471 \n",
      "INFO:Epoch 79 Summary| Validation loss = 1.609413981437683 | Validation loss outcomes = 0.3368159830570221 | Validation loss treatments = 1.2725980281829834\n",
      "INFO:Epoch 80 | total loss = 1.502048134803772 | outcome loss = 0.3109426498413086 | treatment loss = 1.1911054849624634 | current alpha = 0.9993292997390673 \n",
      "INFO:Epoch 80 Summary| Validation loss = 1.592700481414795 | Validation loss outcomes = 0.3357924222946167 | Validation loss treatments = 1.2569080591201782\n",
      "INFO:Epoch 81 | total loss = 1.4990193843841553 | outcome loss = 0.30921047925949097 | treatment loss = 1.1898088455200195 | current alpha = 0.9993931059399423 \n",
      "INFO:Epoch 81 Summary| Validation loss = 1.583638072013855 | Validation loss outcomes = 0.3378642797470093 | Validation loss treatments = 1.2457737922668457\n",
      "INFO:Epoch 82 | total loss = 1.5012671947479248 | outcome loss = 0.3085298240184784 | treatment loss = 1.192737340927124 | current alpha = 0.9994508436877971 \n",
      "INFO:Epoch 82 Summary| Validation loss = 1.589072585105896 | Validation loss outcomes = 0.34448403120040894 | Validation loss treatments = 1.2445886135101318\n",
      "INFO:Epoch 83 | total loss = 1.4959856271743774 | outcome loss = 0.3114456832408905 | treatment loss = 1.1845399141311646 | current alpha = 0.9995030898363211 \n",
      "INFO:Epoch 83 Summary| Validation loss = 1.580723524093628 | Validation loss outcomes = 0.33472561836242676 | Validation loss treatments = 1.2459979057312012\n",
      "INFO:Epoch 84 | total loss = 1.498579502105713 | outcome loss = 0.3020244836807251 | treatment loss = 1.1965550184249878 | current alpha = 0.9995503664595333 \n",
      "INFO:Epoch 84 Summary| Validation loss = 1.5940098762512207 | Validation loss outcomes = 0.33801406621932983 | Validation loss treatments = 1.255995750427246\n",
      "INFO:Epoch 85 | total loss = 1.5164589881896973 | outcome loss = 0.31947430968284607 | treatment loss = 1.1969846487045288 | current alpha = 0.9995931460438896 \n",
      "INFO:Epoch 85 Summary| Validation loss = 1.5708341598510742 | Validation loss outcomes = 0.3365755081176758 | Validation loss treatments = 1.2342586517333984\n",
      "INFO:Epoch 86 | total loss = 1.518654465675354 | outcome loss = 0.30973681807518005 | treatment loss = 1.2089176177978516 | current alpha = 0.9996318561900732 \n",
      "INFO:Epoch 86 Summary| Validation loss = 1.6091059446334839 | Validation loss outcomes = 0.3536311388015747 | Validation loss treatments = 1.2554748058319092\n",
      "INFO:Epoch 87 | total loss = 1.510723352432251 | outcome loss = 0.3103408217430115 | treatment loss = 1.2003824710845947 | current alpha = 0.9996668838704454 \n",
      "INFO:Epoch 87 Summary| Validation loss = 1.5651720762252808 | Validation loss outcomes = 0.33491605520248413 | Validation loss treatments = 1.2302560806274414\n",
      "INFO:Epoch 88 | total loss = 1.5306885242462158 | outcome loss = 0.3095223009586334 | treatment loss = 1.2211662530899048 | current alpha = 0.9996985792838806 \n",
      "INFO:Epoch 88 Summary| Validation loss = 1.5869503021240234 | Validation loss outcomes = 0.334825336933136 | Validation loss treatments = 1.2521249055862427\n",
      "INFO:Epoch 89 | total loss = 1.5210069417953491 | outcome loss = 0.3061799705028534 | treatment loss = 1.2148269414901733 | current alpha = 0.9997272593458408 \n",
      "INFO:Epoch 89 Summary| Validation loss = 1.586106300354004 | Validation loss outcomes = 0.33686548471450806 | Validation loss treatments = 1.249240756034851\n",
      "INFO:Epoch 90 | total loss = 1.4978660345077515 | outcome loss = 0.30381345748901367 | treatment loss = 1.1940525770187378 | current alpha = 0.9997532108480274 \n",
      "INFO:Epoch 90 Summary| Validation loss = 1.5601255893707275 | Validation loss outcomes = 0.3357708752155304 | Validation loss treatments = 1.2243547439575195\n",
      "INFO:Epoch 91 | total loss = 1.495905876159668 | outcome loss = 0.30487900972366333 | treatment loss = 1.1910268068313599 | current alpha = 0.9997766933187409 \n",
      "INFO:Epoch 91 Summary| Validation loss = 1.577712059020996 | Validation loss outcomes = 0.33538925647735596 | Validation loss treatments = 1.2423229217529297\n",
      "INFO:Epoch 92 | total loss = 1.4898533821105957 | outcome loss = 0.30610495805740356 | treatment loss = 1.183748483657837 | current alpha = 0.9997979416121845 \n",
      "INFO:Epoch 92 Summary| Validation loss = 1.5622092485427856 | Validation loss outcomes = 0.33577001094818115 | Validation loss treatments = 1.2264392375946045\n",
      "INFO:Epoch 93 | total loss = 1.5074496269226074 | outcome loss = 0.3140493631362915 | treatment loss = 1.193400263786316 | current alpha = 0.9998171682522956 \n",
      "INFO:Epoch 93 Summary| Validation loss = 1.5778038501739502 | Validation loss outcomes = 0.33536648750305176 | Validation loss treatments = 1.2424373626708984\n",
      "INFO:Epoch 94 | total loss = 1.5386251211166382 | outcome loss = 0.3048427104949951 | treatment loss = 1.233782410621643 | current alpha = 0.9998345655542968 \n",
      "INFO:Epoch 94 Summary| Validation loss = 1.5958712100982666 | Validation loss outcomes = 0.3468361496925354 | Validation loss treatments = 1.2490350008010864\n",
      "INFO:Epoch 95 | total loss = 1.494759440422058 | outcome loss = 0.3046722114086151 | treatment loss = 1.1900871992111206 | current alpha = 0.999850307544979 \n",
      "INFO:Epoch 95 Summary| Validation loss = 1.5843394994735718 | Validation loss outcomes = 0.34575867652893066 | Validation loss treatments = 1.2385808229446411\n",
      "INFO:Epoch 96 | total loss = 1.507967233657837 | outcome loss = 0.30526089668273926 | treatment loss = 1.2027063369750977 | current alpha = 0.9998645517007607 \n",
      "INFO:Epoch 96 Summary| Validation loss = 1.5836302042007446 | Validation loss outcomes = 0.33905237913131714 | Validation loss treatments = 1.2445778846740723\n",
      "INFO:Epoch 97 | total loss = 1.5038297176361084 | outcome loss = 0.3027311861515045 | treatment loss = 1.2010985612869263 | current alpha = 0.9998774405207667 \n",
      "INFO:Epoch 97 Summary| Validation loss = 1.5772331953048706 | Validation loss outcomes = 0.3372098207473755 | Validation loss treatments = 1.2400233745574951\n",
      "INFO:Epoch 98 | total loss = 1.5033533573150635 | outcome loss = 0.30184489488601685 | treatment loss = 1.2015085220336914 | current alpha = 0.9998891029505543 \n",
      "INFO:Epoch 98 Summary| Validation loss = 1.5819443464279175 | Validation loss outcomes = 0.33593153953552246 | Validation loss treatments = 1.246012806892395\n",
      "INFO:Epoch 99 | total loss = 1.4844406843185425 | outcome loss = 0.29936346411705017 | treatment loss = 1.18507719039917 | current alpha = 0.9998996556706323 \n",
      "INFO:Epoch 99 Summary| Validation loss = 1.5652401447296143 | Validation loss outcomes = 0.337127149105072 | Validation loss treatments = 1.228113055229187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish treatment effects model training and testing.\n"
     ]
    }
   ],
   "source": [
    "from treatments.treatments import treatment_effects_model\n",
    "\n",
    "# Set the treatment effects model\n",
    "model_name = 'CRN'\n",
    "projection_horizon = 5\n",
    "\n",
    "# Set up validation for early stopping and best model saving\n",
    "dataset_training.train_val_test_split(prob_val=0.2, prob_test = 0.0)\n",
    "\n",
    "if model_name == 'CRN':\n",
    "    model_parameters={'encoder_rnn_hidden_units': 128,\n",
    "                      'encoder_br_size': 64,\n",
    "                      'encoder_fc_hidden_units':128,\n",
    "                      'encoder_learning_rate': 0.001,\n",
    "                      'encoder_batch_size': 256,\n",
    "                      'encoder_keep_prob': 0.9,\n",
    "                      'encoder_num_epochs': 100,\n",
    "                      'encoder_max_alpha': 1.0,\n",
    "                      'decoder_br_size': 64,\n",
    "                      'decoder_fc_hidden_units': 128,\n",
    "                      'decoder_learning_rate': 0.001,\n",
    "                      'decoder_batch_size': 512,\n",
    "                      'decoder_keep_prob': 0.9,\n",
    "                      'decoder_num_epochs': 100,\n",
    "                      'decoder_max_alpha': 1.0,\n",
    "                      'projection_horizon': 5,\n",
    "                      'static_mode': 'concatenate',\n",
    "                      'time_mode': 'concatenate'}\n",
    "    treatment_model = treatment_effects_model(model_name, model_parameters, task='classification')\n",
    "    treatment_model.fit(dataset_training)\n",
    "    \n",
    "elif model_name == 'RMSN':\n",
    "    hyperparams_encoder_iptw = {\n",
    "        'dropout_rate': 0.1,\n",
    "        'memory_multiplier': 4,\n",
    "        'num_epochs': 100,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_norm': 0.5}\n",
    "\n",
    "    hyperparams_decoder_iptw = {\n",
    "        'dropout_rate': 0.1,\n",
    "        'memory_multiplier': 2,\n",
    "        'num_epochs': 100,\n",
    "        'batch_size': 512,\n",
    "        'learning_rate': 0.001,\n",
    "        'max_norm': 4.0}\n",
    "\n",
    "    model_parameters={'hyperparams_encoder_iptw': hyperparams_encoder_iptw, \n",
    "                      'hyperparams_decoder_iptw': hyperparams_decoder_iptw,\n",
    "                      'static_mode': 'concatenate',\n",
    "                      'time_mode': 'concatenate', \n",
    "                      'model_dir': 'tmp/', \n",
    "                      'model_name': 'rmsn_test'}\n",
    "    treatment_model = treatment_effects_model(model_name, model_parameters, task='classification')\n",
    "    treatment_model.fit(dataset_training, projection_horizon=projection_horizon)\n",
    "    \n",
    "elif model_name == 'GANITE':\n",
    "    hyperparams = {'batch_size': 256, \n",
    "                   'alpha': 1.0, \n",
    "                   'hidden_dims': 128, \n",
    "                   'learning_rate': 0.001, \n",
    "                   'stack_dim': 4}\n",
    "    \n",
    "    model_parameters={'hyperparams': hyperparams,\n",
    "                     'static_mode': 'concatenate',\n",
    "                     'time_mode': 'concatenate',}\n",
    "\n",
    "    #treatment_model = treatment_effects_model(model_name, model_parameters, task='classification')\n",
    "    treatment_model = GANITE_Model(hyperparams=hyperparams, task=task, static_mode='concatenate', time_mode='concatenate')\n",
    "    treatment_model.fit(dataset_training)\n",
    "\n",
    "# Return the factual predictions on the testing set\n",
    "test_y_hat = treatment_model.predict(dataset_testing)\n",
    "\n",
    "print('Finish treatment effects model training and testing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish predictor model evaluation.\n",
      "Overall performance\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 576x360 with 1 Axes>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import Metrics\n",
    "from evaluation import print_performance\n",
    "\n",
    "# Evaluate predictor model\n",
    "metrics = Metrics(metric_sets, metric_parameters)\n",
    "result = metrics.evaluate(dataset_testing.label, test_y_hat)\n",
    "data_point_count = metrics.data_point_count\n",
    "print('Finish predictor model evaluation.')\n",
    "\n",
    "print('Overall performance')\n",
    "print_performance(result, metric_sets, metric_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq_auc': array([0.86267705, 0.90576653, 0.92248623, 0.93797538, 0.91715241,\n",
       "        0.92293042, 0.91780134, 0.9023569 , 0.8968059 , 0.88823529,\n",
       "        0.94481605, 0.92855093, 0.91666667, 0.90932377, 0.88186462,\n",
       "        0.906     , 0.87873754, 0.88461538, 0.80779221,        nan]),\n",
       " 'overall_auc': 0.9072210671247865}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute sequence metrics.\n",
    "r = result['ventilator + auc']\n",
    "d = data_point_count['ventilator + auc']\n",
    "\n",
    "# Compute overall metric.\n",
    "scale = d / np.expand_dims(d.sum(axis=0), axis=0)\n",
    "# print(scale)\n",
    "\n",
    "r_overall_scaled = np.nansum(scale * r, axis=0)\n",
    "r_overall_mean = r_overall_scaled.mean()\n",
    "\n",
    "results_computed = {\n",
    "    \"seq_auc\": r,\n",
    "    \"overall_auc\": r_overall_mean,\n",
    "}\n",
    "\n",
    "results_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.nanmean(result['ventilator + auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize counterfactual estimations\n",
    "\n",
    "(1) Visualize the estimated counterfactual trajectories for user defined treatment options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluation import print_counterfactual_predictions\n",
    "\n",
    "if model_name in ['CRN', 'RMSN']:\n",
    "  # Predict and visualize counterfactuals for the sequence of treatments indicated by the user through the treatment_options\n",
    "  treatment_options = np.array([[[1], [1], [1], [1], [1], [0]],\n",
    "                                  [[0], [0], [0], [0], [1], [1]]])\n",
    "  history, counterfactual_traj = treatment_model.predict_counterfactual_trajectories(dataset=dataset_testing,\n",
    "                                                                            patient_id=2, timestep=2,\n",
    "                                                                            treatment_options=treatment_options)\n",
    "\n",
    "  print_counterfactual_predictions(patient_history=history, treatment_options=treatment_options,\n",
    "                                   counterfactual_predictions=counterfactual_traj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
